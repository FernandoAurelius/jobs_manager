import argparse
import ast
import glob
import logging
import os
import sys


def update_init_py(target_dir: str, verbose: bool = False) -> int:
    logger = logging.getLogger(__name__)

    # Files/directories to exclude from auto-generation
    EXCLUDED_PATHS = {
        "jobs_manager/settings/__init__.py",
        "jobs_manager/__init__.py",  # Main project init
    }

    # Also exclude migration directories - they shouldn't have imports
    if "/migrations" in target_dir:
        logger.info(f"Skipping migration directory: {target_dir}")
        return 0  # Success, but skipped

    init_file = os.path.join(target_dir, "__init__.py")

    # Check if this file should be excluded
    relative_init_path = os.path.relpath(init_file)
    if relative_init_path in EXCLUDED_PATHS:
        logger.info(f"Skipping excluded file: {relative_init_path}")
        return 0  # Success, but skipped

    if not os.path.exists(target_dir):
        logger.error(f"Skipping non-existent folder: {target_dir}")
        return 2  # Error Code 2: Directory does not exist

    py_files = [
        f for f in os.listdir(target_dir) if f.endswith(".py") and f != "__init__.py"
    ]

    if not py_files:
        logger.warning(
            f"No Python files found in {target_dir}. Skipping __init__.py generation."
        )
        return 3  # Error Code 3: No Python files found

    import_lines = [
        "# This file is autogenerated by update_init.py script",
        "",  # Add a blank line before the imports
    ]
    all_exports = []
    import_data = []  # Store (module_name, exports) for sorting

    for py_file in py_files:
        module_name = py_file.replace(".py", "")
        module_path = os.path.join(target_dir, py_file)

        logger.debug(f"Processing file: {module_path}")

        # Parse the file to find class and function definitions
        try:
            with open(module_path, "r") as file:
                tree = ast.parse(file.read())
        except Exception as e:
            logger.error(f"Error parsing {module_path}: {e}")
            continue

        classes = [
            node.name
            for node in ast.walk(tree)
            if isinstance(node, ast.ClassDef)
            and node.name != "Meta"  # Exclude Meta class
        ]

        # Only get top-level functions, not class methods
        functions = [
            node.name
            for node in tree.body
            if isinstance(node, ast.FunctionDef)
            and not node.name.startswith("_")  # Exclude private functions
        ]

        exports = classes + functions
        if exports:
            logger.debug(f"Found classes: {classes}")
            logger.debug(f"Found functions: {functions}")
            import_data.append((module_name, exports))
            all_exports.extend(exports)

    # Sort imports by module name and generate formatted import statements
    import_data.sort(key=lambda x: x[0])
    
    for module_name, exports in import_data:
        # Format imports for readability - use multi-line if many exports
        if len(exports) > 3:
            import_lines.append(f"from .{module_name} import (")
            for export in exports:
                import_lines.append(f"    {export},")
            import_lines.append(")")
        else:
            import_lines.append(f"from .{module_name} import {', '.join(exports)}")

    # Add __all__ definition - remove duplicates, sort alphabetically, and use double quotes
    unique_exports = sorted(
        set(all_exports)
    )  # Remove duplicates and sort alphabetically
    import_lines.append("\n__all__ = [")
    for export_name in unique_exports:
        import_lines.append(f'    "{export_name}",')
    import_lines.append("]")

    # Write to __init__.py
    try:
        with open(init_file, "w") as init_f:
            init_f.write("\n".join(import_lines) + "\n")
        logger.info(f"Successfully updated {init_file}")
        return 0  # Success
    except IOError as e:
        logger.error(f"Failed to write to {init_file}: {e}")
        return 4  # Error Code 4: IOError during file writing


def find_all_init_directories() -> list[str]:
    """Find all directories containing __init__.py files."""
    init_files = glob.glob("**/__init__.py", recursive=True)
    return [os.path.dirname(init_file) for init_file in init_files]


def update_all_init_files(verbose: bool = False) -> int:
    """Update all __init__.py files found in the project."""
    logger = logging.getLogger(__name__)

    directories = find_all_init_directories()
    logger.info(f"Found {len(directories)} directories with __init__.py files")

    total_errors = 0
    success_count = 0

    for directory in directories:
        logger.info(f"Processing: {directory}")
        result = update_init_py(directory, verbose=verbose)
        if result == 0:
            success_count += 1
        else:
            total_errors += 1

    logger.info(f"Completed: {success_count} successful, {total_errors} errors")
    return total_errors


def main() -> None:
    parser = argparse.ArgumentParser(
        description="Automatically update __init__.py with class imports"
    )
    parser.add_argument(
        "target_directory",
        nargs="?",
        help="Directory to process for generating imports in __init__.py (optional - defaults to all)",
    )
    parser.add_argument("--verbose", action="store_true", help="Enable verbose output")
    parser.add_argument(
        "--all", action="store_true", help="Update all __init__.py files in the project"
    )

    args = parser.parse_args()

    # Configure logging
    logging.basicConfig(
        level=logging.DEBUG if args.verbose else logging.INFO,
        format="%(levelname)s: %(message)s",
    )

    # If no target directory is provided, or --all is specified, update all
    if args.target_directory is None or args.all:
        result = update_all_init_files(verbose=args.verbose)
        sys.exit(result)
    else:
        result = update_init_py(args.target_directory, verbose=args.verbose)
        sys.exit(result)


if __name__ == "__main__":
    main()
